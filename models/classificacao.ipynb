{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "smoking-thumb",
   "metadata": {},
   "source": [
    "# Classificação de imagens de leismaniose utilizando CNN pré-treinadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-lemon",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alert-edmonton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 25 22:36:11 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce RTX 208...  On   | 00000000:09:00.0 Off |                  N/A |\n",
      "|  0%   30C    P8     4W / 300W |      5MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce RTX 208...  On   | 00000000:0A:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8     9W / 300W |      5MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  GeForce RTX 208...  On   | 00000000:42:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8     1W / 300W |      5MiB / 11019MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce RTX 208...  On   | 00000000:43:00.0 Off |                  N/A |\n",
      "|  0%   35C    P8    19W / 300W |     16MiB / 11016MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1558      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A      1732      G   /usr/bin/gnome-shell                0MiB |\n",
      "|    1   N/A  N/A      1558      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      1732      G   /usr/bin/gnome-shell                0MiB |\n",
      "|    2   N/A  N/A      1558      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      1732      G   /usr/bin/gnome-shell                0MiB |\n",
      "|    3   N/A  N/A      1558      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    3   N/A  N/A      1732      G   /usr/bin/gnome-shell                4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" #aqui tem q escolher uma das gpus, veja a que esta desocupada (comando: nvidia-smi)\n",
    "tf_device='/gpu:0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-rover",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "announced-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from keras.applications.resnet_v2 import ResNet152V2\n",
    "from keras.applications.densenet import DenseNet201\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "import pickle # salvar modelo em disco\n",
    "\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "proper-nylon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author: Clésio Gonçalves\n",
      "\n",
      "tensorflow: 2.4.1\n",
      "numpy     : 1.19.2\n",
      "matplotlib: 3.3.4\n",
      "pandas    : 1.2.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Versões dos pacotes usados neste jupyter notebook\n",
    "%reload_ext watermark\n",
    "%watermark -a \"Clésio Gonçalves\" --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-generator",
   "metadata": {},
   "source": [
    "## Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "manual-jacket",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dados de entrada\n",
    "PATH_IMAGES = 'dataset/'\n",
    "\n",
    "# Parâmetros do treinamento\n",
    "BATCH_SIZE = 10\n",
    "SEED = 42\n",
    "\n",
    "# K-fold\n",
    "N_SPLIT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ancient-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Remove o diretorio caso exista (antes de criá-lo)\n",
    "if os.path.exists(\"modelo\") and os.path.isdir(\"modelo\"):\n",
    "    shutil.rmtree(\"modelo\")\n",
    "    \n",
    "# Remove o diretorio caso exista (antes de criá-lo)\n",
    "if os.path.exists(\"resultados\") and os.path.isdir(\"resultados\"):\n",
    "    shutil.rmtree(\"resultados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "textile-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir modelo\n",
    "!mkdir resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "covered-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros treinamento\n",
    "epocas_treinamento = 20\n",
    "base_learning_rate = 0.0001\n",
    "\n",
    "epocas_ajuste_fino = 10\n",
    "total_epocas = epocas_treinamento + epocas_ajuste_fino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-magic",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caroline-louis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CATEGORIAS = ['Monkey Pox', 'Others']\n",
    "CATEGORIAS = ['Negativo', 'Positivo']\n",
    "NUM_CATEGORIAS = len(CATEGORIAS)\n",
    "NUM_CATEGORIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "innovative-disability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negativo 72 imagens\n",
      "Positivo 78 imagens\n"
     ]
    }
   ],
   "source": [
    "for category in CATEGORIAS:\n",
    "    print('{} {} imagens'.format(category, len(os.listdir(os.path.join(PATH_IMAGES, category)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wireless-center",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = []\n",
    "for category in CATEGORIAS:\n",
    "    for file in os.listdir(os.path.join(PATH_IMAGES, category)):\n",
    "        dataset.append(['{}/{}'.format(category, file), category])\n",
    "dataset = pd.DataFrame(dataset, columns=['arquivo', 'categoria'])\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "frank-offense",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arquivo</th>\n",
       "      <th>categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negativo/CM200826-124843056.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negativo/CM200826-122443024.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negativo/CM200826-122541026.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negativo/CM200826-144801011.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Negativo/CM200826-144527006.jpg</td>\n",
       "      <td>Negativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Positivo/CM200819-105910047.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Positivo/Imagem 13.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Positivo/CM200826-100032004.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Positivo/Imagem 34.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Positivo/Imagem 40.jpg</td>\n",
       "      <td>Positivo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             arquivo categoria\n",
       "0    Negativo/CM200826-124843056.jpg  Negativo\n",
       "1    Negativo/CM200826-122443024.jpg  Negativo\n",
       "2    Negativo/CM200826-122541026.jpg  Negativo\n",
       "3    Negativo/CM200826-144801011.jpg  Negativo\n",
       "4    Negativo/CM200826-144527006.jpg  Negativo\n",
       "..                               ...       ...\n",
       "145  Positivo/CM200819-105910047.jpg  Positivo\n",
       "146           Positivo/Imagem 13.jpg  Positivo\n",
       "147  Positivo/CM200826-100032004.jpg  Positivo\n",
       "148           Positivo/Imagem 34.jpg  Positivo\n",
       "149           Positivo/Imagem 40.jpg  Positivo\n",
       "\n",
       "[150 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bronze-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo X e Y\n",
    "dataset_x = dataset.arquivo\n",
    "dataset_y = dataset.categoria"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-iceland",
   "metadata": {},
   "source": [
    "# Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spanish-bible",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing Data Generators\n",
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "legitimate-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega os dados de treino, validação e testes\n",
    "def leitura_dados(img_size):\n",
    "    train_dataset = datagen.flow_from_dataframe(dataframe = train_df, \n",
    "                                                      directory = PATH_IMAGES,\n",
    "                                                      x_col = \"arquivo\", \n",
    "                                                      y_col = \"categoria\",\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size = img_size, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      seed = SEED,\n",
    "                                                      shuffle = True)\n",
    "\n",
    "    val_dataset = datagen.flow_from_dataframe(dataframe = val_df, \n",
    "                                                      directory = PATH_IMAGES,\n",
    "                                                      x_col = \"arquivo\", \n",
    "                                                      y_col = \"categoria\",\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size = img_size, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      shuffle = False)\n",
    "\n",
    "    test_dataset = datagen.flow_from_dataframe(dataframe = test_df, \n",
    "                                                      directory = PATH_IMAGES,\n",
    "                                                      x_col = \"arquivo\", \n",
    "                                                      y_col = \"categoria\",\n",
    "                                                      class_mode=\"binary\",\n",
    "                                                      target_size = img_size, \n",
    "                                                      batch_size = BATCH_SIZE,\n",
    "                                                      shuffle = False)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-virtue",
   "metadata": {},
   "source": [
    "# Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "constant-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria data frame de resultados\n",
    "colunas_dataframe = ['model', 'tp', 'fp', 'tn', 'fn', 'accuracy', 'kappa', 'precision', 'f1score', 'recall', 'specificity', 'roc_auc']\n",
    "resultados = pd.DataFrame(columns = colunas_dataframe)\n",
    "\n",
    "def calcula_metricas_binarias(y_true, y_pred):\n",
    "    \n",
    "    global resultados\n",
    "    \n",
    "    # Cutoff\n",
    "    y_true = (y_true > 0.5).flatten()\n",
    "    y_pred = (y_pred > 0.5).flatten()\n",
    "\n",
    "    cm = confusion_matrix(y_true,y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    kappa = cohen_kappa_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1score = f1_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    specificity = (1.0 * tn) / (tn + fp)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    metricas = {'model': models[rede].name, \n",
    "                'tp': tp, \n",
    "                'fp': fp,\n",
    "                'tn': tn,\n",
    "                'fn': fn,\n",
    "                'accuracy': accuracy,\n",
    "                'kappa': kappa,\n",
    "                'precision': precision,\n",
    "                'f1score': f1score,\n",
    "                'recall': recall,\n",
    "                'specificity': specificity,\n",
    "                'roc_auc':roc_auc}\n",
    "    \n",
    "    print(metricas)\n",
    "    \n",
    "    resultados = resultados.append(metricas, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "periodic-mambo",
   "metadata": {},
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "sorted-bridal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leitura dos pesos pré-treinados da ImageNet\n",
    "# Não inclui as camadas de classificação no topo, ideal para extração de features\n",
    "models = [\n",
    "    DenseNet201(weights = \"imagenet\", input_shape = (224, 224, 3), include_top = False),\n",
    "    InceptionV3(weights='imagenet', input_shape=(299, 299, 3), include_top=False),\n",
    "    Xception(weights='imagenet', input_shape=(299, 299, 3), include_top=False),\n",
    "    InceptionResNetV2(weights='imagenet', input_shape=(299, 299, 3), include_top=False),\n",
    "    NASNetLarge(weights='imagenet', input_shape=(331, 331, 3), include_top=False),\n",
    "    ResNet152V2(weights='imagenet', input_shape=(224, 224, 3), include_top=False)\n",
    "]\n",
    "\n",
    "# Reescala dos valores dos pixels do modelo\n",
    "processamento_input = [\n",
    "    keras.applications.densenet.preprocess_input,\n",
    "    keras.applications.inception_v3.preprocess_input,\n",
    "    keras.applications.xception.preprocess_input,\n",
    "    keras.applications.inception_resnet_v2.preprocess_input,\n",
    "    keras.applications.nasnet.preprocess_input,\n",
    "    keras.applications.resnet_v2.preprocess_input\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "thirty-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir um modelo a partir de redes neurais pré-treinadas\n",
    "def modelo_base(rede):\n",
    "    \n",
    "    base_model = models[rede]\n",
    "    img_size = (base_model.input.shape[1], base_model.input.shape[2])\n",
    "    \n",
    "    # Processa as entradas do modelo\n",
    "    preprocess_input = processamento_input[rede]\n",
    "    \n",
    "    return base_model, img_size, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "found-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando aumento de dados aleatórios somente no fit (treinamento)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        #keras.layers.experimental.preprocessing.RandomRotation(0.9), \n",
    "        keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "        keras.layers.experimental.preprocessing.RandomContrast(0.2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bound-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir modelo\n",
    "def build_model():\n",
    "    \n",
    "    # Freeze the base_model\n",
    "    # Congela a base convolucional antes de compilar e treinar o modelo\n",
    "    # Evita que os pesos em uma determinada camada sejam atualizados durante o treinamento\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Arquitetura do modelo básico\n",
    "    # base_model.summary()\n",
    "\n",
    "    # Adiciona o cabeçalho de classificação\n",
    "    # Converter as features do shape `base_model.output_shape[1:] para vectores\n",
    "    global_average_layer = keras.layers.GlobalAveragePooling2D()\n",
    "\n",
    "    # Aplica uma camada densa para converter essas features em uma única previsão por imagem\n",
    "    # Os números > 0.5 preveem a classe 1, os números <= 0.5 preveem a classe 0\n",
    "    prediction_layer = keras.layers.Dense(1, activation=\"sigmoid\", name='predictions') # Função de ativação sigmoid adicionada\n",
    "\n",
    "    # Modelo encadeando as camadas de aumento de dados, reescalonamento, base_model e extrator de features\n",
    "    img_shape = img_size + (3,)\n",
    "    inputs = keras.Input(shape = img_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "    x = preprocess_input(x)\n",
    "    x = base_model(x, training=False)\n",
    "    x = global_average_layer(x)\n",
    "    x = keras.layers.Dropout(0.2)(x)\n",
    "    outputs = prediction_layer(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "everyday-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile o modelo antes de treiná-lo\n",
    "def compile_model(learning_rate):\n",
    "    \n",
    "    # Compilar modelo\n",
    "    # Não especifiquei o batch_size, pois os dados já estão em conjuntos (batchs)\n",
    "    model.compile(optimizer = Adam(lr = learning_rate), loss = keras.losses.BinaryCrossentropy(), metrics = ['binary_accuracy'])\n",
    "    \n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fitted-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos um checkpoint para verificar regularmente se a perda em validação diminuiu\n",
    "# Se a performance melhorar em validação salvamos o modelo\n",
    "# Podemos ainda optar por salvar o modelo a cada número de épocas\n",
    "# callbacks\n",
    "# Redução gradual da taxa de aprendizado (Reduce on Plateau)\n",
    "def get_callbacks():\n",
    "    return [EarlyStopping(monitor = 'val_loss', patience = 10, verbose = 1),\n",
    "            ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, min_lr = 0.0000001, verbose = 1),\n",
    "            ModelCheckpoint('modelo/{}.h5'.format(models[rede].name), \n",
    "                         verbose = 1, \n",
    "                         save_best_only = True, \n",
    "                         save_weights_only = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "finished-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva o modelo\n",
    "def salva_estrutura_modelo():\n",
    "    \n",
    "    # salva o modelo em disco\n",
    "    # pickle.dump(model, open(f'modelo/{models[rede].name}.pkl', 'wb'))\n",
    "    model.save(f'modelo/{models[rede].name}')\n",
    "    \n",
    "    # salva json\n",
    "    arquivo_modelo = f'modelo/{models[rede].name}.json'\n",
    "    modelo_json = model.to_json()\n",
    "    with open(arquivo_modelo, 'w') as json_file:\n",
    "        json_file.write(modelo_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "identified-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento do modelo\n",
    "def treinamento_model(qnt_epocas, epoca_inicial):\n",
    "    \n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs = qnt_epocas,\n",
    "                        initial_epoch = epoca_inicial,\n",
    "                        validation_data = val_dataset,\n",
    "                        verbose=1,\n",
    "                        callbacks = get_callbacks())\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "middle-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de aprendizado da precisão / perda de treinamento e validação ao usar o modelo\n",
    "def aprendizado_treinamento():\n",
    "    \n",
    "    metricas_graficos = [\"loss\", \"binary_accuracy\"]\n",
    "          \n",
    "    fig, ax = plt.subplots(len(metricas_graficos), 1, figsize=(10, len(metricas_graficos)*6))\n",
    "    ax = ax.ravel()\n",
    "    dados_x = np.arange(1, epocas_treinamento+1, 1)\n",
    "\n",
    "    for i, met in enumerate(metricas_graficos):        \n",
    "        ax[i].plot(dados_x, history.history[met], label='Training ' + met)\n",
    "        ax[i].plot(dados_x, history.history[\"val_\" + met], label='Validation ' + met)\n",
    "        ax[i].set_title(\"Training and Validation %s in model %s\" %(met, models[rede].name))\n",
    "        ax[i].set_xlabel(\"epochs\")\n",
    "        ax[i].set_ylabel(met)\n",
    "        \n",
    "        if (i != 0): # loss function\n",
    "            ax[i].legend(loc='lower right')\n",
    "        else:\n",
    "            ax[i].legend(loc='upper right')\n",
    "    \n",
    "    return metricas_graficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "announced-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMIAR PARA AJUSTE FINO (OPCIONAL)\n",
    "# Definir as camadas inferiores como não treináveis\n",
    "def limiar_ajuste_fino():\n",
    "    \n",
    "    # Exibe a quantidade de camadas do modelo base\n",
    "    # print(\"Número de camadas no modelo base: \", len(base_model.layers))\n",
    "\n",
    "    # Ajuste fino desta camada em diante\n",
    "    fine_tune_at = 100\n",
    "\n",
    "    # Congele todas as camadas antes da camada 'fine_tune_at'\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "negative-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuste fino\n",
    "def ajuste_fino():\n",
    "    \n",
    "    # Foi treinado apenas algumas camadas do modelo. \n",
    "    # Os pesos da rede pré-treinada não foram atualizados durante o treinamento.\n",
    "    # Uma maneira de aumentar ainda mais o desempenho é treinar (ou \"ajustar\") os pesos das camadas superiores \n",
    "    # do modelo pré-treinado junto com o treinamento do classificador adicionado (camada de classificação adicionada)\n",
    "    # Descongelar as camadas superiores do modelo (descongelar base_model)\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Limiar ajuste fino (OPCIONAL)\n",
    "    limiar_ajuste_fino()\n",
    "    \n",
    "    # É necessário recompilar o modelo (para que essas alterações tenham efeito)\n",
    "    # É importante usar uma taxa de aprendizado mais baixa neste estágio, \n",
    "    # pois está usando um modelo muito maior e deseja readaptar os pesos pré-treinados\n",
    "    compile_model(base_learning_rate/10)\n",
    "    \n",
    "    # Retomar o treinamento melhorará sua precisão em alguns pontos percentuais\n",
    "    # history.epoch[-1] é a última época do ultimo treinamento\n",
    "    history_fine = treinamento_model(total_epocas, history.epoch[-1]+1)\n",
    "    \n",
    "    return history_fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "contemporary-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curvas de aprendizado da precisão / perda de treinamento e validação ao ajustar as últimas camadas do modelo\n",
    "def aprendizado_ajuste_fino():\n",
    "    \n",
    "    fig, ax = plt.subplots(len(metricas_graficos), 1, figsize=(12, len(metricas_graficos)*6))\n",
    "    ax = ax.ravel()\n",
    "    dados_x = np.arange(1, len(history.history['loss']) + len(history_fine.history['loss'])+1, 1)\n",
    "\n",
    "    for i, met in enumerate(metricas_graficos):\n",
    "        dados_treino = history.history[met] + history_fine.history[met]\n",
    "        dados_validacao = history.history[\"val_\" + met] + history_fine.history[\"val_\" + met]\n",
    "        \n",
    "        ax[i].plot(dados_x, dados_treino, label='Training ' + met)\n",
    "        ax[i].plot(dados_x, dados_validacao, label='Validation ' + met)\n",
    "        ax[i].plot([epocas_treinamento, epocas_treinamento], plt.ylim(), label='Start Fine Tuning')\n",
    "        ax[i].set_title(\"Training and Validation %s in model %s\" %(met, models[rede].name))\n",
    "        ax[i].set_xlabel(\"epochs\")\n",
    "        ax[i].set_ylabel(met)\n",
    "        \n",
    "        if (i != 0): # loss function\n",
    "            ax[i].legend(loc='lower right')\n",
    "        else:\n",
    "            ax[i].legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transsexual-medicine",
   "metadata": {},
   "source": [
    "# Treinamento K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "communist-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================\n",
      "Iteração 1 de 5\n",
      "======================================================\n",
      "\n",
      "Executando modelo densenet201\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 13s 563ms/step - loss: 0.9007 - binary_accuracy: 0.3047 - val_loss: 0.7467 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74668, saving model to modelo/densenet201.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.8336 - binary_accuracy: 0.3684 - val_loss: 0.7273 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74668 to 0.72726, saving model to modelo/densenet201.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.7571 - binary_accuracy: 0.5443 - val_loss: 0.7136 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.72726 to 0.71359, saving model to modelo/densenet201.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.8210 - binary_accuracy: 0.3202 - val_loss: 0.6976 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.71359 to 0.69757, saving model to modelo/densenet201.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.7506 - binary_accuracy: 0.4651 - val_loss: 0.6899 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.69757 to 0.68989, saving model to modelo/densenet201.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.6997 - binary_accuracy: 0.5762 - val_loss: 0.6766 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68989 to 0.67656, saving model to modelo/densenet201.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.7350 - binary_accuracy: 0.5012 - val_loss: 0.6591 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.67656 to 0.65907, saving model to modelo/densenet201.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.7963 - binary_accuracy: 0.4424 - val_loss: 0.6547 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.65907 to 0.65469, saving model to modelo/densenet201.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.7905 - binary_accuracy: 0.4579 - val_loss: 0.6441 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.65469 to 0.64410, saving model to modelo/densenet201.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.7567 - binary_accuracy: 0.4321 - val_loss: 0.6348 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.64410 to 0.63475, saving model to modelo/densenet201.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.7460 - binary_accuracy: 0.4548 - val_loss: 0.6209 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.63475 to 0.62093, saving model to modelo/densenet201.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.7365 - binary_accuracy: 0.5846 - val_loss: 0.6130 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.62093 to 0.61304, saving model to modelo/densenet201.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 246ms/step - loss: 0.7287 - binary_accuracy: 0.5386 - val_loss: 0.6075 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.61304 to 0.60746, saving model to modelo/densenet201.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 235ms/step - loss: 0.6413 - binary_accuracy: 0.5227 - val_loss: 0.5961 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.60746 to 0.59611, saving model to modelo/densenet201.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.6728 - binary_accuracy: 0.5830 - val_loss: 0.5884 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.59611 to 0.58841, saving model to modelo/densenet201.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.6053 - binary_accuracy: 0.6783 - val_loss: 0.5809 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.58841 to 0.58090, saving model to modelo/densenet201.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.6350 - binary_accuracy: 0.6468 - val_loss: 0.5734 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.58090 to 0.57337, saving model to modelo/densenet201.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.6227 - binary_accuracy: 0.5985 - val_loss: 0.5660 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.57337 to 0.56596, saving model to modelo/densenet201.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.5844 - binary_accuracy: 0.7007 - val_loss: 0.5562 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.56596 to 0.55625, saving model to modelo/densenet201.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.6049 - binary_accuracy: 0.6623 - val_loss: 0.5492 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.55625 to 0.54919, saving model to modelo/densenet201.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 17s 475ms/step - loss: 0.5833 - binary_accuracy: 0.7193 - val_loss: 0.3356 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.33556, saving model to modelo/densenet201.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.2945 - binary_accuracy: 0.9006 - val_loss: 0.2491 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.33556 to 0.24915, saving model to modelo/densenet201.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 227ms/step - loss: 0.1363 - binary_accuracy: 0.9583 - val_loss: 0.2054 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.24915 to 0.20536, saving model to modelo/densenet201.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.0794 - binary_accuracy: 0.9810 - val_loss: 0.2087 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.20536\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.0680 - binary_accuracy: 0.9927 - val_loss: 0.3011 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.20536\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.0522 - binary_accuracy: 0.9882 - val_loss: 0.2107 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.20536\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 289ms/step - loss: 0.0358 - binary_accuracy: 1.0000 - val_loss: 0.2353 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.20536\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.0573 - binary_accuracy: 0.9816 - val_loss: 0.2789 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.20536\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.0288 - binary_accuracy: 1.0000 - val_loss: 0.2764 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.20536\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.0318 - binary_accuracy: 0.9942 - val_loss: 0.3086 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.20536\n",
      "INFO:tensorflow:Assets written to: modelo/densenet201/assets\n",
      "3/3 [==============================] - 4s 354ms/step\n",
      "{'model': 'densenet201', 'tp': 14, 'fp': 0, 'tn': 15, 'fn': 1, 'accuracy': 0.9666666666666667, 'kappa': 0.9333333333333333, 'precision': 1.0, 'f1score': 0.9655172413793104, 'recall': 0.9333333333333333, 'specificity': 1.0, 'roc_auc': 0.9666666666666667}\n",
      "\n",
      "Executando modelo inception_v3\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 7s 358ms/step - loss: 0.6856 - binary_accuracy: 0.5216 - val_loss: 0.7103 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71025, saving model to modelo/inception_v3.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.7207 - binary_accuracy: 0.5481 - val_loss: 0.6866 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71025 to 0.68662, saving model to modelo/inception_v3.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.7011 - binary_accuracy: 0.5463 - val_loss: 0.6814 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68662 to 0.68142, saving model to modelo/inception_v3.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.6996 - binary_accuracy: 0.6123 - val_loss: 0.6679 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.68142 to 0.66787, saving model to modelo/inception_v3.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 0.6611 - binary_accuracy: 0.6539 - val_loss: 0.6613 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66787 to 0.66134, saving model to modelo/inception_v3.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.6041 - binary_accuracy: 0.6740 - val_loss: 0.6454 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.66134 to 0.64541, saving model to modelo/inception_v3.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.6322 - binary_accuracy: 0.6538 - val_loss: 0.6337 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.64541 to 0.63369, saving model to modelo/inception_v3.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 6s 534ms/step - loss: 0.6149 - binary_accuracy: 0.6316 - val_loss: 0.6274 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.63369 to 0.62735, saving model to modelo/inception_v3.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.5887 - binary_accuracy: 0.7073 - val_loss: 0.6192 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.62735 to 0.61916, saving model to modelo/inception_v3.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.5838 - binary_accuracy: 0.7283 - val_loss: 0.6061 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61916 to 0.60607, saving model to modelo/inception_v3.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.5638 - binary_accuracy: 0.7311 - val_loss: 0.5801 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.60607 to 0.58006, saving model to modelo/inception_v3.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.5939 - binary_accuracy: 0.7484 - val_loss: 0.5719 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58006 to 0.57186, saving model to modelo/inception_v3.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.5753 - binary_accuracy: 0.7514 - val_loss: 0.5597 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.57186 to 0.55966, saving model to modelo/inception_v3.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5697 - binary_accuracy: 0.7515 - val_loss: 0.5563 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55966 to 0.55627, saving model to modelo/inception_v3.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 243ms/step - loss: 0.5663 - binary_accuracy: 0.7037 - val_loss: 0.5638 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.55627\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.5429 - binary_accuracy: 0.7027 - val_loss: 0.5592 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.55627\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.5022 - binary_accuracy: 0.8206 - val_loss: 0.5481 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.55627 to 0.54815, saving model to modelo/inception_v3.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.5235 - binary_accuracy: 0.7274 - val_loss: 0.5398 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.54815 to 0.53980, saving model to modelo/inception_v3.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 237ms/step - loss: 0.4879 - binary_accuracy: 0.8196 - val_loss: 0.5253 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.53980 to 0.52534, saving model to modelo/inception_v3.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.4800 - binary_accuracy: 0.8513 - val_loss: 0.5133 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.52534 to 0.51330, saving model to modelo/inception_v3.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 8s 341ms/step - loss: 0.5012 - binary_accuracy: 0.7372 - val_loss: 0.3642 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.36422, saving model to modelo/inception_v3.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.3287 - binary_accuracy: 0.8699 - val_loss: 0.3436 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.36422 to 0.34361, saving model to modelo/inception_v3.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.1968 - binary_accuracy: 0.9561 - val_loss: 0.2749 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.34361 to 0.27486, saving model to modelo/inception_v3.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.1621 - binary_accuracy: 0.9652 - val_loss: 0.2701 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.27486 to 0.27013, saving model to modelo/inception_v3.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.0632 - binary_accuracy: 0.9863 - val_loss: 0.4006 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.27013\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.0553 - binary_accuracy: 0.9857 - val_loss: 0.3456 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.27013\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.0309 - binary_accuracy: 1.0000 - val_loss: 0.3350 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.27013\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.0226 - binary_accuracy: 0.9965 - val_loss: 0.2904 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.27013\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.0681 - binary_accuracy: 0.9698 - val_loss: 0.2595 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.27013 to 0.25954, saving model to modelo/inception_v3.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.0076 - binary_accuracy: 1.0000 - val_loss: 0.2471 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.25954 to 0.24708, saving model to modelo/inception_v3.h5\n",
      "INFO:tensorflow:Assets written to: modelo/inception_v3/assets\n",
      "3/3 [==============================] - 2s 358ms/step\n",
      "{'model': 'inception_v3', 'tp': 12, 'fp': 1, 'tn': 14, 'fn': 3, 'accuracy': 0.8666666666666667, 'kappa': 0.7333333333333334, 'precision': 0.9230769230769231, 'f1score': 0.8571428571428571, 'recall': 0.8, 'specificity': 0.9333333333333333, 'roc_auc': 0.8666666666666667}\n",
      "\n",
      "Executando modelo xception\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 5s 327ms/step - loss: 0.6699 - binary_accuracy: 0.5714 - val_loss: 0.7039 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.70392, saving model to modelo/xception.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.6806 - binary_accuracy: 0.5248 - val_loss: 0.7013 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.70392 to 0.70134, saving model to modelo/xception.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.6828 - binary_accuracy: 0.5690 - val_loss: 0.7013 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70134 to 0.70127, saving model to modelo/xception.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.6586 - binary_accuracy: 0.6093 - val_loss: 0.6989 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.70127 to 0.69893, saving model to modelo/xception.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.6586 - binary_accuracy: 0.6114 - val_loss: 0.6926 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.69893 to 0.69260, saving model to modelo/xception.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.6522 - binary_accuracy: 0.6631 - val_loss: 0.6863 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69260 to 0.68629, saving model to modelo/xception.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.6423 - binary_accuracy: 0.6738 - val_loss: 0.6829 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68629 to 0.68286, saving model to modelo/xception.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.6138 - binary_accuracy: 0.7447 - val_loss: 0.6790 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.68286 to 0.67901, saving model to modelo/xception.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.6365 - binary_accuracy: 0.6772 - val_loss: 0.6818 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.67901\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.6262 - binary_accuracy: 0.6775 - val_loss: 0.6731 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.67901 to 0.67311, saving model to modelo/xception.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6020 - binary_accuracy: 0.6645 - val_loss: 0.6675 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.67311 to 0.66752, saving model to modelo/xception.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.6016 - binary_accuracy: 0.8259 - val_loss: 0.6563 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.66752 to 0.65630, saving model to modelo/xception.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.6187 - binary_accuracy: 0.7168 - val_loss: 0.6529 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.65630 to 0.65289, saving model to modelo/xception.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 0.5846 - binary_accuracy: 0.7704 - val_loss: 0.6483 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.65289 to 0.64827, saving model to modelo/xception.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.5752 - binary_accuracy: 0.8117 - val_loss: 0.6424 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.64827 to 0.64236, saving model to modelo/xception.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.6026 - binary_accuracy: 0.7562 - val_loss: 0.6408 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.64236 to 0.64083, saving model to modelo/xception.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.5586 - binary_accuracy: 0.7920 - val_loss: 0.6404 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.64083 to 0.64039, saving model to modelo/xception.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.5742 - binary_accuracy: 0.7958 - val_loss: 0.6368 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.64039 to 0.63680, saving model to modelo/xception.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.5912 - binary_accuracy: 0.7335 - val_loss: 0.6291 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.63680 to 0.62914, saving model to modelo/xception.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.5348 - binary_accuracy: 0.8585 - val_loss: 0.6252 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.62914 to 0.62523, saving model to modelo/xception.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 5s 311ms/step - loss: 0.5586 - binary_accuracy: 0.7495 - val_loss: 0.5885 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.58851, saving model to modelo/xception.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.4806 - binary_accuracy: 0.8663 - val_loss: 0.5553 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.58851 to 0.55532, saving model to modelo/xception.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.4071 - binary_accuracy: 0.9106 - val_loss: 0.4976 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.55532 to 0.49759, saving model to modelo/xception.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.3230 - binary_accuracy: 0.9222 - val_loss: 0.4526 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.49759 to 0.45258, saving model to modelo/xception.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.3338 - binary_accuracy: 0.8765 - val_loss: 0.4293 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.45258 to 0.42933, saving model to modelo/xception.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.2289 - binary_accuracy: 0.9577 - val_loss: 0.3986 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.42933 to 0.39856, saving model to modelo/xception.h5\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 240ms/step - loss: 0.2002 - binary_accuracy: 0.9574 - val_loss: 0.3846 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.39856 to 0.38464, saving model to modelo/xception.h5\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 228ms/step - loss: 0.2240 - binary_accuracy: 0.9176 - val_loss: 0.3570 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.38464 to 0.35704, saving model to modelo/xception.h5\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 229ms/step - loss: 0.1733 - binary_accuracy: 0.9364 - val_loss: 0.3288 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.35704 to 0.32885, saving model to modelo/xception.h5\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.1275 - binary_accuracy: 0.9940 - val_loss: 0.3172 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.32885 to 0.31724, saving model to modelo/xception.h5\n",
      "INFO:tensorflow:Assets written to: modelo/xception/assets\n",
      "3/3 [==============================] - 2s 358ms/step\n",
      "{'model': 'xception', 'tp': 12, 'fp': 0, 'tn': 15, 'fn': 3, 'accuracy': 0.9, 'kappa': 0.8, 'precision': 1.0, 'f1score': 0.888888888888889, 'recall': 0.8, 'specificity': 1.0, 'roc_auc': 0.9}\n",
      "\n",
      "Executando modelo inception_resnet_v2\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 13s 500ms/step - loss: 0.7092 - binary_accuracy: 0.5123 - val_loss: 0.7532 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75324, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.7116 - binary_accuracy: 0.5415 - val_loss: 0.7358 - val_binary_accuracy: 0.3750\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75324 to 0.73578, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.7284 - binary_accuracy: 0.4869 - val_loss: 0.7334 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73578 to 0.73345, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.7496 - binary_accuracy: 0.3972 - val_loss: 0.7228 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73345 to 0.72279, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.6714 - binary_accuracy: 0.6200 - val_loss: 0.7168 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.72279 to 0.71685, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.6951 - binary_accuracy: 0.5662 - val_loss: 0.6936 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.71685 to 0.69358, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 0.6767 - binary_accuracy: 0.5965 - val_loss: 0.6920 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.69358 to 0.69197, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.6447 - binary_accuracy: 0.5922 - val_loss: 0.7062 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69197\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.6369 - binary_accuracy: 0.5988 - val_loss: 0.7046 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69197\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.6832 - binary_accuracy: 0.5327 - val_loss: 0.6743 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.69197 to 0.67426, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.6775 - binary_accuracy: 0.5221 - val_loss: 0.6727 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.67426 to 0.67274, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.6624 - binary_accuracy: 0.5377 - val_loss: 0.6595 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.67274 to 0.65954, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.6679 - binary_accuracy: 0.5369 - val_loss: 0.6531 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.65954 to 0.65315, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.6425 - binary_accuracy: 0.6262 - val_loss: 0.6575 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.65315\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 252ms/step - loss: 0.6185 - binary_accuracy: 0.6682 - val_loss: 0.6830 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.65315\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 0.6435 - binary_accuracy: 0.5685 - val_loss: 0.6635 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.65315\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 274ms/step - loss: 0.6450 - binary_accuracy: 0.6096 - val_loss: 0.6376 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.65315 to 0.63757, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 238ms/step - loss: 0.6491 - binary_accuracy: 0.6355 - val_loss: 0.6333 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.63757 to 0.63328, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 250ms/step - loss: 0.5812 - binary_accuracy: 0.7137 - val_loss: 0.6220 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.63328 to 0.62202, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.5932 - binary_accuracy: 0.7375 - val_loss: 0.6154 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.62202 to 0.61535, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 17s 516ms/step - loss: 0.5962 - binary_accuracy: 0.5428 - val_loss: 0.4167 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.41672, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.4459 - binary_accuracy: 0.8142 - val_loss: 0.3222 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.41672 to 0.32221, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.2890 - binary_accuracy: 0.8798 - val_loss: 0.1939 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.32221 to 0.19394, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 261ms/step - loss: 0.1444 - binary_accuracy: 0.9340 - val_loss: 0.1858 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.19394 to 0.18580, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.1175 - binary_accuracy: 0.9493 - val_loss: 0.1310 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.18580 to 0.13096, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.1107 - binary_accuracy: 0.9413 - val_loss: 0.0654 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.13096 to 0.06539, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.0525 - binary_accuracy: 0.9913 - val_loss: 0.3025 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.06539\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 269ms/step - loss: 0.0549 - binary_accuracy: 0.9863 - val_loss: 0.0610 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.06539 to 0.06103, saving model to modelo/inception_resnet_v2.h5\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.0317 - binary_accuracy: 0.9776 - val_loss: 0.4320 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.06103\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 3s 257ms/step - loss: 0.0189 - binary_accuracy: 0.9822 - val_loss: 0.0340 - val_binary_accuracy: 1.0000\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.06103 to 0.03405, saving model to modelo/inception_resnet_v2.h5\n",
      "INFO:tensorflow:Assets written to: modelo/inception_resnet_v2/assets\n",
      "3/3 [==============================] - 5s 366ms/step\n",
      "{'model': 'inception_resnet_v2', 'tp': 14, 'fp': 0, 'tn': 15, 'fn': 1, 'accuracy': 0.9666666666666667, 'kappa': 0.9333333333333333, 'precision': 1.0, 'f1score': 0.9655172413793104, 'recall': 0.9333333333333333, 'specificity': 1.0, 'roc_auc': 0.9666666666666667}\n",
      "\n",
      "Executando modelo NASNet\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 23s 801ms/step - loss: 0.6767 - binary_accuracy: 0.5534 - val_loss: 0.7561 - val_binary_accuracy: 0.3125\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75611, saving model to modelo/NASNet.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 251ms/step - loss: 0.6630 - binary_accuracy: 0.6311 - val_loss: 0.7311 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75611 to 0.73113, saving model to modelo/NASNet.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.6348 - binary_accuracy: 0.6515 - val_loss: 0.7064 - val_binary_accuracy: 0.4375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73113 to 0.70638, saving model to modelo/NASNet.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 267ms/step - loss: 0.6402 - binary_accuracy: 0.6874 - val_loss: 0.6858 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.70638 to 0.68578, saving model to modelo/NASNet.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.6120 - binary_accuracy: 0.7220 - val_loss: 0.6715 - val_binary_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68578 to 0.67154, saving model to modelo/NASNet.h5\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 275ms/step - loss: 0.5937 - binary_accuracy: 0.7937 - val_loss: 0.6558 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.67154 to 0.65584, saving model to modelo/NASNet.h5\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.5682 - binary_accuracy: 0.7485 - val_loss: 0.6489 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.65584 to 0.64895, saving model to modelo/NASNet.h5\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 264ms/step - loss: 0.5664 - binary_accuracy: 0.7752 - val_loss: 0.6361 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.64895 to 0.63614, saving model to modelo/NASNet.h5\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.5405 - binary_accuracy: 0.8759 - val_loss: 0.6257 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.63614 to 0.62573, saving model to modelo/NASNet.h5\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 258ms/step - loss: 0.5538 - binary_accuracy: 0.8102 - val_loss: 0.6171 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.62573 to 0.61713, saving model to modelo/NASNet.h5\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 274ms/step - loss: 0.5148 - binary_accuracy: 0.8157 - val_loss: 0.6074 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61713 to 0.60744, saving model to modelo/NASNet.h5\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.4941 - binary_accuracy: 0.8964 - val_loss: 0.5926 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.60744 to 0.59258, saving model to modelo/NASNet.h5\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 268ms/step - loss: 0.4966 - binary_accuracy: 0.8321 - val_loss: 0.5876 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.59258 to 0.58762, saving model to modelo/NASNet.h5\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 0.5024 - binary_accuracy: 0.8407 - val_loss: 0.5819 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.58762 to 0.58194, saving model to modelo/NASNet.h5\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 3s 254ms/step - loss: 0.4868 - binary_accuracy: 0.8952 - val_loss: 0.5788 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.58194 to 0.57883, saving model to modelo/NASNet.h5\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.4983 - binary_accuracy: 0.7883 - val_loss: 0.5724 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.57883 to 0.57243, saving model to modelo/NASNet.h5\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.4711 - binary_accuracy: 0.8855 - val_loss: 0.5603 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.57243 to 0.56034, saving model to modelo/NASNet.h5\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 0.4488 - binary_accuracy: 0.8923 - val_loss: 0.5505 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.56034 to 0.55047, saving model to modelo/NASNet.h5\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.4727 - binary_accuracy: 0.8526 - val_loss: 0.5403 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.55047 to 0.54027, saving model to modelo/NASNet.h5\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.4800 - binary_accuracy: 0.8654 - val_loss: 0.5370 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.54027 to 0.53700, saving model to modelo/NASNet.h5\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 32s 952ms/step - loss: 0.4879 - binary_accuracy: 0.7933 - val_loss: 0.6105 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00021: val_loss improved from inf to 0.61054, saving model to modelo/NASNet.h5\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 6s 517ms/step - loss: 0.3931 - binary_accuracy: 0.8390 - val_loss: 0.4514 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.61054 to 0.45142, saving model to modelo/NASNet.h5\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 6s 531ms/step - loss: 0.3175 - binary_accuracy: 0.8297 - val_loss: 0.3796 - val_binary_accuracy: 0.8125\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.45142 to 0.37958, saving model to modelo/NASNet.h5\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 6s 533ms/step - loss: 0.1693 - binary_accuracy: 0.9584 - val_loss: 0.3598 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.37958 to 0.35985, saving model to modelo/NASNet.h5\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 6s 540ms/step - loss: 0.0833 - binary_accuracy: 0.9896 - val_loss: 0.4873 - val_binary_accuracy: 0.7500\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.35985\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 6s 527ms/step - loss: 0.0928 - binary_accuracy: 0.9501 - val_loss: 0.3954 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.35985\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 6s 524ms/step - loss: 0.0381 - binary_accuracy: 0.9820 - val_loss: 0.4294 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.35985\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 6s 525ms/step - loss: 0.0592 - binary_accuracy: 0.9704 - val_loss: 0.4049 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.35985\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 6s 527ms/step - loss: 0.0120 - binary_accuracy: 1.0000 - val_loss: 0.4237 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.35985\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 6s 524ms/step - loss: 0.0122 - binary_accuracy: 1.0000 - val_loss: 0.4222 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.35985\n",
      "INFO:tensorflow:Assets written to: modelo/NASNet/assets\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fda311123a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 7s 360ms/step\n",
      "{'model': 'NASNet', 'tp': 11, 'fp': 0, 'tn': 15, 'fn': 4, 'accuracy': 0.8666666666666667, 'kappa': 0.7333333333333334, 'precision': 1.0, 'f1score': 0.846153846153846, 'recall': 0.7333333333333333, 'specificity': 1.0, 'roc_auc': 0.8666666666666667}\n",
      "\n",
      "Executando modelo resnet152v2\n",
      "Found 104 validated image filenames belonging to 2 classes.\n",
      "Found 16 validated image filenames belonging to 2 classes.\n",
      "Found 30 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 10s 430ms/step - loss: 1.1077 - binary_accuracy: 0.4912 - val_loss: 0.7638 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76383, saving model to modelo/resnet152v2.h5\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 3s 256ms/step - loss: 1.0627 - binary_accuracy: 0.5070 - val_loss: 0.7146 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76383 to 0.71465, saving model to modelo/resnet152v2.h5\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 1.0459 - binary_accuracy: 0.4336 - val_loss: 0.6950 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.71465 to 0.69499, saving model to modelo/resnet152v2.h5\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 3s 255ms/step - loss: 0.8835 - binary_accuracy: 0.4215 - val_loss: 0.6930 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69499 to 0.69302, saving model to modelo/resnet152v2.h5\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.9158 - binary_accuracy: 0.3769 - val_loss: 0.7038 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.69302\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.8715 - binary_accuracy: 0.3919 - val_loss: 0.7153 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.69302\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 3s 225ms/step - loss: 0.7890 - binary_accuracy: 0.4890 - val_loss: 0.7183 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.69302\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 0.7851 - binary_accuracy: 0.4767 - val_loss: 0.7210 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.69302\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 3s 253ms/step - loss: 0.7298 - binary_accuracy: 0.5277 - val_loss: 0.7181 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.69302\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.7883 - binary_accuracy: 0.4754 - val_loss: 0.7163 - val_binary_accuracy: 0.5625\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.69302\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.6777 - binary_accuracy: 0.6152 - val_loss: 0.7147 - val_binary_accuracy: 0.6250\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.69302\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 3s 231ms/step - loss: 0.7741 - binary_accuracy: 0.5669 - val_loss: 0.7130 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.69302\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.8091 - binary_accuracy: 0.4718 - val_loss: 0.7114 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.69302\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.6768 - binary_accuracy: 0.6259 - val_loss: 0.7104 - val_binary_accuracy: 0.6875\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.69302\n",
      "Epoch 00014: early stopping\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 14s 415ms/step - loss: 0.7058 - binary_accuracy: 0.5485 - val_loss: 0.4801 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00015: val_loss improved from inf to 0.48013, saving model to modelo/resnet152v2.h5\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 3s 236ms/step - loss: 0.4276 - binary_accuracy: 0.8601 - val_loss: 0.2643 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.48013 to 0.26428, saving model to modelo/resnet152v2.h5\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 3s 248ms/step - loss: 0.3461 - binary_accuracy: 0.8262 - val_loss: 0.2191 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.26428 to 0.21913, saving model to modelo/resnet152v2.h5\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 3s 239ms/step - loss: 0.2765 - binary_accuracy: 0.8747 - val_loss: 0.1911 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.21913 to 0.19114, saving model to modelo/resnet152v2.h5\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.1695 - binary_accuracy: 0.9042 - val_loss: 0.2379 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.19114\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 0.1386 - binary_accuracy: 0.9350 - val_loss: 0.2968 - val_binary_accuracy: 0.8750\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.19114\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 3s 241ms/step - loss: 0.1443 - binary_accuracy: 0.9619 - val_loss: 0.3515 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.19114\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 3s 247ms/step - loss: 0.1599 - binary_accuracy: 0.9358 - val_loss: 0.2935 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.19114\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 3s 262ms/step - loss: 0.0674 - binary_accuracy: 0.9707 - val_loss: 0.2994 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.19114\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 3s 249ms/step - loss: 0.0182 - binary_accuracy: 1.0000 - val_loss: 0.3079 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.19114\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 3s 244ms/step - loss: 0.0179 - binary_accuracy: 1.0000 - val_loss: 0.3120 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.19114\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 3s 263ms/step - loss: 0.0263 - binary_accuracy: 1.0000 - val_loss: 0.3195 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.19114\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 3s 260ms/step - loss: 0.0234 - binary_accuracy: 1.0000 - val_loss: 0.3266 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.19114\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 3s 226ms/step - loss: 0.0120 - binary_accuracy: 1.0000 - val_loss: 0.3353 - val_binary_accuracy: 0.9375\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.19114\n",
      "Epoch 00028: early stopping\n",
      "INFO:tensorflow:Assets written to: modelo/resnet152v2/assets\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdd844ac310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 4s 352ms/step\n",
      "{'model': 'resnet152v2', 'tp': 11, 'fp': 0, 'tn': 15, 'fn': 4, 'accuracy': 0.8666666666666667, 'kappa': 0.7333333333333334, 'precision': 1.0, 'f1score': 0.846153846153846, 'recall': 0.7333333333333333, 'specificity': 1.0, 'roc_auc': 0.8666666666666667}\n",
      "CPU times: user 19min 13s, sys: 44.6 s, total: 19min 58s\n",
      "Wall time: 20min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# k-fold\n",
    "kfold = StratifiedKFold(n_splits = N_SPLIT, shuffle = True, random_state = SEED)\n",
    "\n",
    "# Contador de iterações do k-fold\n",
    "iteracao = 1\n",
    "\n",
    "# K-fold treino e teste de cada divisão\n",
    "for train_idx, test_idx in list(kfold.split(dataset_x, dataset_y)):\n",
    "    \n",
    "    print(\"\\n======================================================\")\n",
    "    print(\"Iteração {} de {}\".format(iteracao, N_SPLIT))\n",
    "    print(\"======================================================\")\n",
    "    \n",
    "    trein_temp = dataset.iloc[train_idx]\n",
    "    test_df = dataset.iloc[test_idx] # 20% teste\n",
    "    \n",
    "    # dividir o teste em validação e teste\n",
    "    train_df, val_df = train_test_split(trein_temp, test_size = 0.13, random_state = SEED) # 10% validação e 70% treino\n",
    "    \n",
    "    for rede in range(len(models)): # Todos os modelos\n",
    "        \n",
    "        print('\\nExecutando modelo {}'.format(models[rede].name))\n",
    "\n",
    "        # Modelo base\n",
    "        base_model, img_size, preprocess_input = modelo_base(rede)\n",
    "\n",
    "        # Leitura dos dados\n",
    "        train_dataset, val_dataset, test_dataset = leitura_dados(img_size)\n",
    "\n",
    "        # Construir modelo\n",
    "        model = build_model()\n",
    "\n",
    "        # Compilar Modelo\n",
    "        compile_model(base_learning_rate)\n",
    "\n",
    "        # Treinamento do modelo\n",
    "        history = treinamento_model(epocas_treinamento, 0)\n",
    "\n",
    "        # Curvas de aprendizado da precisão / perda de treinamento e validação ao usar o modelo\n",
    "        # metricas_graficos = aprendizado_treinamento()\n",
    "\n",
    "        # Ajuste fino\n",
    "        history_fine = ajuste_fino()\n",
    "\n",
    "        # Curvas de aprendizado da precisão / perda de treinamento e validação ao ajustar as últimas camadas do modelo\n",
    "        # aprendizado_ajuste_fino()\n",
    "        \n",
    "        # Carrega o melhor modelo\n",
    "        model.load_weights('modelo/{}.h5'.format(models[rede].name))\n",
    "        \n",
    "        # Salva a estrutura do modelo\n",
    "        salva_estrutura_modelo()\n",
    "\n",
    "        # Obtemos os rótulos verdadeiros\n",
    "        y_true = np.array(test_dataset.classes)\n",
    "\n",
    "        # Obtemos os rótulos previstos\n",
    "        y_pred = model.predict(test_dataset, verbose = 1)\n",
    "        # y_pred = previsoes.argmax(axis=1)\n",
    "\n",
    "        # Calcula métricas Binárias\n",
    "        calcula_metricas_binarias(y_true, y_pred)\n",
    "\n",
    "        # Limpa a sessão\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "    iteracao = iteracao + 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "occupied-kansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fn</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>kappa</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1score</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>densenet201</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inception_v3</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xception</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inception_resnet_v2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NASNet</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>resnet152v2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  tp fp  tn fn  accuracy     kappa  precision   f1score  \\\n",
       "0          densenet201  14  0  15  1  0.966667  0.933333   1.000000  0.965517   \n",
       "1         inception_v3  12  1  14  3  0.866667  0.733333   0.923077  0.857143   \n",
       "2             xception  12  0  15  3  0.900000  0.800000   1.000000  0.888889   \n",
       "3  inception_resnet_v2  14  0  15  1  0.966667  0.933333   1.000000  0.965517   \n",
       "4               NASNet  11  0  15  4  0.866667  0.733333   1.000000  0.846154   \n",
       "5          resnet152v2  11  0  15  4  0.866667  0.733333   1.000000  0.846154   \n",
       "\n",
       "     recall  specificity   roc_auc  \n",
       "0  0.933333     1.000000  0.966667  \n",
       "1  0.800000     0.933333  0.866667  \n",
       "2  0.800000     1.000000  0.900000  \n",
       "3  0.933333     1.000000  0.966667  \n",
       "4  0.733333     1.000000  0.866667  \n",
       "5  0.733333     1.000000  0.866667  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "excellent-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados de todas as iterações\n",
    "resultados.to_csv('resultados/resultados.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
